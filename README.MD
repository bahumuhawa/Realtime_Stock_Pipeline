# ğŸ“˜ Realtime Stock Market Data Pipeline
A complete real-time data engineering pipeline that streams live stock prices, processes them using PySpark, stores analytics in PostgreSQL, and makes them available for reporting tools like Power BI.


Built using the required stack: **Python, Kafka, PySpark, PostgreSQL, Power BI**.

---


# ğŸ”§ Features


* **Python Producer**: Fetches real-time stock data from Alpha Vantage and sends it to Kafka.
* **Kafka**: Serves as the message broker for real-time streaming.
* **PySpark Structured Streaming**: Reads Kafka topics, processes data (moving averages, volume), and writes results to PostgreSQL.
* **PostgreSQL**: Stores both raw and processed market data.
* **Power BI**: Connects to PostgreSQL for visualization and reporting.


---


# ğŸ“‚ Project Structure


```
realtime_stock_pipeline/
â”‚
â”œâ”€â”€ producer/producer.py        # Python â†’ Kafka ingestion
â”œâ”€â”€ spark/spark_streaming.py    # Kafka â†’ PySpark â†’ PostgreSQL
â”œâ”€â”€ db/schema.sql               # DB tables and indexes
â”œâ”€â”€ docker-compose.yml          # Kafka, Zookeeper, PostgreSQL
â”œâ”€â”€ requirements.txt            # Python dependencies
```

---

# âš™ï¸ Quick Start

### 1. Start Docker Services


```bash
docker-compose up -d
```


### 2. Apply Database Schema


```bash
psql -h localhost -U postgres -d marketdb -f db/schema.sql
```


### 3. Install Python Dependencies


```bash
pip install -r requirements.txt
```


### 4. Set API Key and Run Producer


```bash
export ALPHA_VANTAGE_KEY=your_api_key_here
python producer/producer.py
```


### 5. Run PySpark Streaming Job


```bash
spark-submit \
 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1 \
 spark/spark_streaming.py
```


---


# ğŸ“Š Power BI Connection


1. Open Power BI Desktop â†’ **Get Data** â†’ *PostgreSQL*.
2. Enter connection details:


```
Host: localhost
Database: marketdb
User: postgres
Password: postgres
```


3. Load tables:


* `symbol_metrics`
* `ticks` (optional)


---


# ğŸ“ Notes

* Alpha Vantage has rate limits; streaming frequency should be controlled.
* For production: add retries, monitoring, and Kafka partitions.

